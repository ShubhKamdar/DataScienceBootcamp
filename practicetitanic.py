# -*- coding: utf-8 -*-
"""PracticeTitanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aIhb08F_ToiYK0pp4eY5ta8JfpLUtVwG

# Practice
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""##Load in the data"""

traindata=pd.read_csv('/content/drive/MyDrive/Titanic/train.csv')
testdata=pd.read_csv('/content/drive/MyDrive/Titanic/test.csv')
GenderSubmissiondata=pd.read_csv('/content/drive/MyDrive/Titanic/gender_submission.csv')

"""##Cleaning Data and Preparing the Data"""

traindata.head()

#Looked at the data in the excel and found that some people had a different title apart from Mr and Miss
#But the main issue is that this title is present in the middle of the name hece will have to split and strip in a weird manner
traindata['PassengerTitle'] = traindata['Name'].str.split(',').str[1].str.strip()
#This wil remove the First word of the name, Now we will strip again to get title which is the first word of the column now
traindata['PassengerTitle'] = traindata['PassengerTitle'].str.split('.').str[0].str.strip()
traindata.head()

traindata['PassengerTitle'].value_counts()

#This works here since the Survived are in a Binary input
Survival_Rate_Based_On_Title=traindata.groupby('PassengerTitle')['Survived'].sum()/traindata['PassengerTitle'].value_counts()
Survival_Rate_Based_On_Title

#Checked Kaggle first to find the columns that had null Values
traindata.loc[traindata['Age'].isna(),'Age']

PercentOfMissingAgeData=(177/891) *100
PercentOfMissingAgeData

traindata['Age'].mean()

traindata.loc[traindata['Age'].isna(),'Age']=traindata['Age'].mean()
traindata['Age'] = traindata['Age'].round().astype(int)
traindata['Age'].mode()

#Initially had decided to drop the Cabin table
#But after some research found that only 1/3 of the people on the ship could have a cabin Which is similar to the not null values in the dataset
Missing_inputs_in_Cabin_column_percentage=(traindata['Cabin'].isna().sum()/len(traindata['Cabin'])) * 100
Missing_inputs_in_Cabin_column_percentage

#Fillinng the missing values in the cabin section with letter N
traindata['Cabin'].fillna('N',inplace=True)

#Converted all the inputs to string and used [0] to extract the first letter which is the Cabin Letter
#Converted all the inputs to string and used [1:] to extract the first letter which is the Cabin Number
traindata['CabinLetter']=traindata['Cabin'].apply(lambda x: str(x)[0])
traindata['CabinNumber']=traindata['Cabin'].apply(lambda x: str(x)[1:])

#Might have to drop CabinNumber based on the number of different values
traindata['CabinLetter'].value_counts()
traindata['CabinNumber'].value_counts()

#Need to use () for Group by and use [] for putting the filter
Percentage_Of_People_Surving_In_Each_Cabin=traindata.groupby('CabinLetter')['Survived'].sum()/traindata['CabinLetter'].value_counts()
Percentage_Of_People_Surving_In_Each_Cabin

#Trying to use Ticket column here to find if there is a certain type of differnce between people with a letter in their ticket
x=0
for i in traindata['Ticket']:
  if i.isnumeric():
    x=x+1
x

traindata['TicketNumber']=traindata['Ticket'].apply(lambda x: x.isnumeric())

traindata.head()

#Somehow can't replace False values with 1, hence replaced them with 0 and true with 1
traindata['TicketNumber'] = traindata['TicketNumber'].replace(False, 0)
traindata['TicketNumber'] = traindata['TicketNumber'].replace(True, 1)
traindata.head()

traindata['TicketNumber'].value_counts()

#Based on our insights here the Ticket column is more or less useless since the survival rate is not affected by the letter on the ticket
Ticket_with_letter_survival_rate=traindata.groupby('TicketNumber')['Survived'].sum()/traindata['TicketNumber'].value_counts()
Ticket_with_letter_survival_rate

traindata.head()

#Dropping passengerId, Cabin, Ticket and TicketNumber since based on our previous work they are not required
traindata.columns
traindata=traindata.drop(columns=['PassengerId','Cabin','Name','Ticket','CabinNumber'])
traindata.columns

traindata.loc[traindata['Age'].notna() & traindata['Embarked'].isna()]

# Had to use [0] in the first line since the mode returns a pandas series and we just want the first element of the series
mostcommonvalueinembarked=traindata['Embarked'].mode()[0]
traindata.loc[traindata['Embarked'].isna(),'Embarked']=mostcommonvalueinembarked
traindata.loc[traindata['Embarked'].isna(),'Embarked']

"""#Light Exploratory Analysis"""

cleantraindata=traindata

cleantraindata.columns

cols=['Pclass', 'Age', 'SibSp', 'Parch',
       'Fare']
for c in cols:
  sns.jointplot(x=c,y='Survived',data=traindata,kind='reg',height=3)
plt.show()

cols=['Pclass', 'Age', 'SibSp', 'Parch',
       'Fare']
for c in cols:
  sns.distplot(traindata[c])
  plt.grid()
  plt.show()

"""#ML Algorithms finally lessgooookvvvfsdccvigvbcvvjc

#Logistic Regression

#Model
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

cleantraindata["Survived"] = cleantraindata["Survived"].astype(int)
X= cleantraindata.drop("Survived", axis=1)
y = cleantraindata["Survived"]

X=pd.get_dummies(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

lr=LogisticRegression()

lr.fit(X_train,y_train)

y_pred = lr.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
accuracy

coefficients = lr.coef_[0]
coefficient_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})
coefficient_df['AbsCoefficient'] = coefficient_df['Coefficient'].abs()
coefficient_df = coefficient_df.sort_values(by='AbsCoefficient', ascending=False)
plt.figure(figsize=(10, 6))
plt.bar(coefficient_df['Feature'], coefficient_df['Coefficient'])
plt.xlabel('Feature')
plt.ylabel('Coefficient')
plt.title('What Factors affected the Survival of individuals')
plt.xticks(rotation=45, ha='right')
plt.show()

"""###Other dataset



"""

testdata=pd.read_csv('/content/drive/MyDrive/Titanic/test.csv')

testdata['PassengerTitle'] = testdata['Name'].str.split(',').str[1].str.strip()
testdata['PassengerTitle'] = testdata['PassengerTitle'].str.split('.').str[0].str.strip()
testdata.head()

testdata.loc[testdata['Age'].isna(),'Age']=testdata['Age'].mean()
testdata['Age'] = testdata['Age'].round().astype(int)
testdata['Age'].mode()

testdata['Cabin'].fillna('N',inplace=True)

testdata['CabinLetter']=testdata['Cabin'].apply(lambda x: str(x)[0])
testdata['CabinNumber']=testdata['Cabin'].apply(lambda x: str(x)[1:])

testdata['TicketNumber']=testdata['Ticket'].apply(lambda x: x.isnumeric())

testdata['TicketNumber'] = testdata['TicketNumber'].replace(False, 0)
testdata['TicketNumber'] = testdata['TicketNumber'].replace(True, 1)
testdata.head()

most_common_value_in_embarked=testdata['Embarked'].mode()[0]
testdata.loc[traindata['Embarked'].isna(),'Embarked']=most_common_value_in_embarked
testdata.loc[traindata['Embarked'].isna(),'Embarked']

testdata=testdata.drop(columns=['PassengerId','Cabin','Name','Ticket','CabinNumber'])

print(testdata.isnull().sum())

testdata = testdata.dropna()

print(testdata.isnull().sum())

cleantestdata=testdata

cleantestdata.head()

Xtest = cleantestdata

X_test=pd.get_dummies(X_test)