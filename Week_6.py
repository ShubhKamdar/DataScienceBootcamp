# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aZc5zlWLj7FZuWfa5t8YqPpTbNBFDjCZ
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_absolute_error, mean_squared_error

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

import warnings
warnings.filterwarnings('ignore')
pd.set_option("display.max_columns", 101)

"""Loading data"""

df = pd.read_csv("https://raw.githubusercontent.com/kartikjindgar/NYU-DataScience-Bootcamp-Fall23/main/Week6/train.csv")

"""Cleaning Data"""

df = df.drop(columns=['id', 'timestamp','country'])
df.loc[df['hours_per_week'].isna(), 'hours_per_week'] = df['hours_per_week'].median()
df.loc[df['telecommute_days_per_week'].isna(), 'telecommute_days_per_week'] = df['telecommute_days_per_week'].median()
df = df.dropna()

cat_cols = [c for c in df.columns if df[c].dtype == 'object'
            and c not in ['is_manager', 'certifications']]
cat_data = df[cat_cols]
print("Categorical Features: ", cat_cols)
binary_cols = ['is_manager', 'certifications']
for c in binary_cols:
    df[c] = df[c].replace(to_replace=['Yes'], value=1)
    df[c] = df[c].replace(to_replace=['No'], value=0)

encodedata = pd.get_dummies(df, columns=cat_cols, drop_first= True)
print("Shape- ", encodedata.shape)

y = encodedata['salary']
X = encodedata.drop(columns=['salary'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
print("Training shape:", X_train.shape)
print("Test shape:", X_test.shape)

int_cols = ['job_years','hours_per_week','telecommute_days_per_week']
scaler = StandardScaler()
scaler.fit(X_train[int_cols])
X_train[int_cols] = scaler.transform(X_train[int_cols])

"""Logistic Regression"""

lr = LinearRegression()
lr.fit(X_train, y_train)
print(lr.coef_)
print(lr.intercept_)

predicted = lr.predict(X_train)
print( mean_absolute_error(y_train, predicted))
print( mean_squared_error(y_train, predicted)**0.5)

X_test[int_cols] = scaler.transform(X_test[int_cols])
predicted = lr.predict(X_test)

print( mean_absolute_error(y_test, predicted))
print( mean_squared_error(y_test, predicted)**0.5)

"""Ridge and Lasso"""

ridge = Ridge(alpha=1)
ridge.fit(X_train,y_train)
ridge_predicted = ridge.predict(X_test)
print( mean_absolute_error(y_test, ridge_predicted))
print( mean_squared_error(y_test, ridge_predicted)**0.5)

lasso = Lasso(alpha=1)
lasso.fit(X_train,y_train)
lasso_predicted = lasso.predict(X_test)
print( mean_absolute_error(y_test, lasso_predicted))
print( mean_squared_error(y_test, lasso_predicted)**0.5)

"""Decision tree"""

dt = DecisionTreeRegressor(max_depth = 10, min_samples_split = 5)
dt.fit(X_train, y_train)
dt_predicted = dt.predict(X_train)
print( mean_absolute_error(y_train, dt_predicted))

dt_predicted = dt.predict(X_test)
print( mean_absolute_error(y_test, dt_predicted))

DT2 = DecisionTreeRegressor(max_depth = 10, min_samples_split = 6)
DT2.fit(X_train, y_train)
Train_pred = DT2.predict(X_train)
Test_pred = DT2.predict(X_test)
print(mean_absolute_error(y_train, Train_pred))
print(mean_absolute_error(y_test, Test_pred))

DT3 = DecisionTreeRegressor(max_depth = 9, min_samples_split = 5)
DT3.fit(X_train, y_train)
Train_pred = DT3.predict(X_train)
Test_pred = DT3.predict(X_test)
print(mean_absolute_error(y_train, Train_pred))
print(mean_absolute_error(y_test, Test_pred))


DT4 = DecisionTreeRegressor(max_depth = 8, min_samples_split = 4)
DT4.fit(X_train, y_train)
Train_pred = DT4.predict(X_train)
Test_pred = DT4.predict(X_test)
print(mean_absolute_error(y_train, Train_pred))
print(mean_absolute_error(y_test, Test_pred))